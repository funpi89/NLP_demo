{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertTokenizer.ipynb",
      "provenance": [],
      "mount_file_id": "1MGAAcKapuzKdH-2Yc7tQbzbg57m4TsV6",
      "authorship_tag": "ABX9TyNqtJQPmVT/YvVK18U9k2Vp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/funpi89/NLP_demo/blob/master/BertTokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tewzpos2tOeY",
        "colab_type": "text"
      },
      "source": [
        "# Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltlEVxXjtF98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R1GlSghvWWH",
        "colab_type": "code",
        "outputId": "9a60095a-c851-4258-ccfa-abe0d28cde00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/2a/79f44178ac6f5b6995bc7804898fce2654da70e0c5c7f76332748420d6fd/bert-for-tf2-0.13.5.tar.gz (40kB)\n",
            "\r\u001b[K     |████████▏                       | 10kB 25.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 20kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 30kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 3.8MB/s \n",
            "\u001b[?25hCollecting py-params>=0.7.3\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/aa/a143f0193a4fb5c7f8aa816b30366e441ff6ffe6cda4887e4c01300c4b01/py-params-0.8.3.tar.gz\n",
            "Collecting params-flow>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/12/2604f88932f285a473015a5adabf08496d88dad0f9c1228fab1547ccc9b5/params-flow-0.7.4.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.7.1->bert-for-tf2) (1.17.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.7.1->bert-for-tf2) (4.28.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.13.5-cp36-none-any.whl size=29948 sha256=5866ae47413c4af054d99107a8fbefc61011983eaee786d523b4479fb4aa9ad8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/11/48/86aff8a0442aa4728c921027a4100ac28878e9d977e76e2d52\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.8.3-cp36-none-any.whl size=4690 sha256=de2888fe05038a009832d0bc4b15ae720a5d6d489e099e02bb99e62cdc47bf3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/98/f8/502fc6b5a7c969276f611efeef0d074c871092d38672203b27\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.7.4-cp36-none-any.whl size=16195 sha256=257b78099613542e1562e7983470be755a5cc2b48d6bb7e7ffa761e02def25d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/30/40/507b60d68b67ac87f35e95c98f5b296a32f146d5ae1d1d5aa7\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.13.5 params-flow-0.7.4 py-params-0.8.3\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 7.6MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op2_NqsIv2hF",
        "colab_type": "code",
        "outputId": "8906d85c-faef-4da2-bae8-44f82b98b732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except: \n",
        "  pass\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ6ocVOPwUEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uguk_w18wmVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S3sJuuqxa6Q",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k04oVercxhHA",
        "colab_type": "text"
      },
      "source": [
        "## loading files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUjgv4-Pw6cE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
        "data = pd.read_csv('/content/drive/My Drive/modern_NLP/train.csv', header=None, names=cols, engine='python', \n",
        "                   encoding='latin1')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEk8pX6MystM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop([\"id\", \"date\", \"query\", \"user\"], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXfANBSnzC-v",
        "colab_type": "code",
        "outputId": "bd1abdae-b56f-4ac8-9949-279e7a41c9b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9FLRNUkzK2u",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RywIlX9zEmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_tweet(tweet):\n",
        "  tweet = BeautifulSoup(tweet, 'lxml').get_text()\n",
        "  tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ',tweet)\n",
        "  tweet = re.sub(r\"https?://[A-Za-z0-9./]+\",\" \", tweet)\n",
        "  tweet = re.sub(r\"[^a-zA-Z.!?]\", \" \",tweet)\n",
        "  tweet = re.sub(r\" +\", \" \",tweet)\n",
        "  return tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKKaTMHs01lR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clean = data['text'].apply(clean_tweet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eixgk4Gw1HmL",
        "colab_type": "code",
        "outputId": "aded5b33-d8bd-465b-d56a-4250720b600a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "data_labels = data['sentiment']\n",
        "data_labels[data_labels == 4] = 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqP58oKB3UAe",
        "colab_type": "text"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsGlR3772UYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB48dmpi4_Z9",
        "colab_type": "code",
        "outputId": "913ea0b2-426c-4715-8c26-27b5c0d5b8e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.tokenize(\"My dog's habbit is running.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my', 'dog', \"'\", 's', 'ha', '##bb', '##it', 'is', 'running', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYqxYh_o5KBm",
        "colab_type": "code",
        "outputId": "f840fc03-5b4e-434d-fdf2-6fac37411e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"My dog is running.\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2026, 3899, 2003, 2770, 1012]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFhEWJEU5Res",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_sentence(sent):\n",
        "  return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4uljgMj5hAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_inputs = data_clean.apply(encode_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHylYHe57COQ",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTXH0lBN5qFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_with_len = [[sent, data_labels[i], len(sent)] for i, sent in enumerate(data_inputs)]\n",
        "random.shuffle(data_with_len)\n",
        "data_with_len.sort(key=lambda x: x[2])\n",
        "sorted_all = [(sent_lab[0], sent_lab[1]) for sent_lab in data_with_len if sent_lab[2] > 7]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf-pJvTa9BZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all, output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqdz2qlF9c0g",
        "colab_type": "code",
        "outputId": "2b80564e-6ba6-4cae-c752-f65174da18d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "next(iter(all_dataset))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=int32, numpy=array([4241, 6862,  999, 2821, 1045, 2293, 2009,  999], dtype=int32)>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E-nKSPE9f8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ),()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxYxhg1P-FFR",
        "colab_type": "code",
        "outputId": "0e2e5b3f-09b2-4907-92c3-d1f3df53b677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "next(iter(all_batched))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 8), dtype=int32, numpy=\n",
              " array([[ 4241,  6862,   999,  2821,  1045,  2293,  2009,   999],\n",
              "        [ 2024,  2017,  3809,  1029,  1029,  2008, 19237,  4757],\n",
              "        [ 1012,  1012,  4283,  2005,  6276,  2009,  2125,  4365],\n",
              "        [ 7929,  2053,  2062, 10821, 14032,   999,  2293,  2166],\n",
              "        [ 2026,  2540,  2180,  1056,  2292,  2017,  2175,   999],\n",
              "        [10916,  2049,  2980,  1999,  2026,  8239, 20996, 17650],\n",
              "        [ 2339,  2079,  2017,  2562, 24234,  2075,  6207,  1012],\n",
              "        [ 2183,  2000,  3335,  3725,  2015,  2288,  5848,   999],\n",
              "        [ 3504,  2066,  1037,  2524,  4632,  1999,  2023,  2028],\n",
              "        [ 9712,  2057,  2293,  2017,  2041,  2182,  1999,  6027],\n",
              "        [ 1055,  1043, 14945,  1055,  2031,  2351, 12300,  7249],\n",
              "        [ 1051,  2053,  4189,   999,  8549,  3407,  5798,  2295],\n",
              "        [ 2074,  2288,  2188,  2189, 19613,  2131,  2012,  2033],\n",
              "        [ 3067,  2064,  2191, 15174,  2021,  2097,  2025,  3153],\n",
              "        [ 8945, 12171, 12171, 12171,  5596, 14141, 14141,  2094],\n",
              "        [ 6554,  2585, 10220,  2000,  1056, 28394,  2102,  1012],\n",
              "        [ 2439,  2026, 17022,  2393,  2033,  2424,  2032,  7382],\n",
              "        [ 1996,  2208,  2003,  2006,  4542,  8536,  2005,  2085],\n",
              "        [ 3336,  4133,  2102,  2078,  1996, 18401,  3793,  2033],\n",
              "        [ 2034,  2674,  2188,  2598,  1998,  2027,  2439,   999],\n",
              "        [ 2821,  2008,  2428, 27136,  2015,   999,   999,   999],\n",
              "        [ 5292,  3270,  2204,  1012,  2049,  1037,  2933,  2059],\n",
              "        [20976,  2021,  2009,  2001,  1037,  2843,  1997,  4569],\n",
              "        [10047,  6015,  2123,  2102,  8011,  2033,  2000,  3109],\n",
              "        [10474,  2006,  1996, 18059,  2347,  2102,  2551,  2077],\n",
              "        [ 2009,  1055, 24057,  2153,  2191,  2009,  2175,  2185],\n",
              "        [ 3100,  8740,  2140,  2156,  2017,  3784,  1012,  1012],\n",
              "        [ 2079,  2023,  4708,  2440,  4708,  1012,  1012,  1012],\n",
              "        [ 3835,  2028,  8788,   999,  5959,  2009,  6775,  2100],\n",
              "        [ 2009,  1055,  2183,  2000,  2022,  1037,  2204,  2154],\n",
              "        [ 2008,  1055, 12476,   999,  5959,  1996,  9609,   999],\n",
              "        [ 2084,  2595, 14556,  2050,  2360,  7632,  7955,   999]],\n",
              "       dtype=int32)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "        0, 0, 0, 0, 1, 0, 1, 1, 1, 1], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma3olUid-NEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NB_BATCHES = math.ceil(len(sorted_all) // BATCH_SIZE)\n",
        "NB_BATCHES_TEST = NB_BATCHES // 10\n",
        "all_batched.shuffle(NB_BATCHES)\n",
        "test_dataset = all_batched.take(NB_BATCHES_TEST)\n",
        "train_dataset = all_batched.skip(NB_BATCHES_TEST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_a-a8NSAvrW",
        "colab_type": "text"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OclWQf4E_9Im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCNN(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, emb_dim=128, nb_filters=50, FFN_units=512, nb_classes=2, dropout_rate=0.1,\n",
        "               training=False, name='dcnn'):\n",
        "    super(DCNN, self).__init__(name=name)\n",
        "    \n",
        "    self.embedding = layers.Embedding(vocab_size, emb_dim)\n",
        "    self.bigram = layers.Conv1D(filters=nb_filters, kernel_size=2, padding='valid', activation='relu')\n",
        "    self.trigram = layers.Conv1D(filters=nb_filters, kernel_size=3, padding='valid', activation='relu')\n",
        "    self.fourgram = layers.Conv1D(filters=nb_filters, kernel_size=4, padding='valid', activation='relu')\n",
        "    self.pool = layers.GlobalMaxPooling1D()\n",
        "    self.dense_1 = layers.Dense(units=FFN_units, activation='relu')\n",
        "    self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "    if nb_classes == 2:\n",
        "      self.last_layer = layers.Dense(units=1, activation='sigmoid')\n",
        "    else:\n",
        "      self.last_layer = layers.Dense(units=nb_classes, activation='softmax')\n",
        "\n",
        "  def call(self, inputs, training):\n",
        "    x = self.embedding(inputs)\n",
        "    x_1 = self.bigram(x)\n",
        "    x_1 = self.pool(x_1)\n",
        "\n",
        "    x_2 = self.trigram(x)\n",
        "    x_2 = self.pool(x_2)\n",
        "\n",
        "    x_3 = self.fourgram(x)\n",
        "    x_3 = self.pool(x_3)\n",
        "\n",
        "    merged = tf.concat([x_1, x_2, x_3], axis=-1) #(batch, 3*nb_filters)\n",
        "    merged = self.dense_1(merged)\n",
        "    merged = self.dropout(merged, training)\n",
        "    output = self.last_layer(merged)\n",
        "    \n",
        "    return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh4-oJIeF4_c",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUZC_QZNFUd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "NB_FILTERS = 100\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 2\n",
        "DROPOUT_RATE = 0.2\n",
        "NB_EPOCHES = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLz10OFPGV7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dcnn = DCNN(vocab_size=VOCAB_SIZE, emb_dim=EMB_DIM, nb_filters=NB_FILTERS,\n",
        "            FFN_units=FFN_UNITS, nb_classes=NB_CLASSES, dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw7lJB0cG2U7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if NB_CLASSES == 2:\n",
        "  Dcnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "else:\n",
        "  Dcnn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4CdF8W7HgFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoints_path = '/content/drive/My Drive/modern_NLP/ckptbert/'\n",
        "ckpt = tf.train.Checkpoint(Dcnn = Dcnn)\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoints_path, max_to_keep=1)\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print('Latest checkpoint restored!!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2dhc1LTJzbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    ckpt_manager.save()\n",
        "    print(\"Checkpoint saved at {}\".format(checkpoints_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6oNHOCgKYXh",
        "colab_type": "code",
        "outputId": "a80e6028-06bc-4f88-8447-8c88a86603ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "Dcnn.fit(train_dataset, epochs=1, callbacks=[MyCustomCallback()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  36913/Unknown - 2328s 63ms/step - loss: 0.4122 - accuracy: 0.8118Checkpoint saved at /content/drive/My Drive/modern_NLP/ckptbert/\n",
            "36913/36913 [==============================] - 2329s 63ms/step - loss: 0.4122 - accuracy: 0.8118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff198366390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBpai9ICXuc0",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hQMYFrtKwE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results =  Dcnn.evaluate(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJYbwo2RX8bX",
        "colab_type": "code",
        "outputId": "46ceb3d2-21d8-4caa-f8e1-67ca1a1c32a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.366759982983809, 0.8409306]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNfoILJyYKcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_prediction(sentence):\n",
        "  tokens = encode_sentence(sentence)\n",
        "  inputs = tf.expand_dims(tokens, 0)\n",
        "  output = Dcnn(inputs, training=False)\n",
        "  sentiment = math.floor(output*2)\n",
        "  if sentiment == 0:\n",
        "    print('output of the model: {}\\nPredicted sentiment: negative'.format(output))\n",
        "  else:\n",
        "    print('output of the model: {}\\nPredicted sentiment: positive'.format(output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRlJ2C6-Z4IF",
        "colab_type": "code",
        "outputId": "f560f8cb-5df6-4340-9318-c9643c0200a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "get_prediction('this movie is so interesting')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output of the model: [[0.973313]]\n",
            "Predicted sentiment: positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trPnilDhaAqu",
        "colab_type": "code",
        "outputId": "4ad36c8c-fe76-40c9-ea2d-8240b27d4304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "get_prediction('this movie is so boring')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output of the model: [[0.0826827]]\n",
            "Predicted sentiment: negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx3CCQiUaFdV",
        "colab_type": "code",
        "outputId": "39e4916e-60c4-47c8-a1ee-96bf9ba1e179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "get_prediction('hahahahahahahaha')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output of the model: [[0.9127056]]\n",
            "Predicted sentiment: positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOAwyMqTaH_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}